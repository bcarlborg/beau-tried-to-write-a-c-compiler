#!/usr/bin/env node

const { debug } = require('console');
const { verify } = require('crypto');
const fs = require('fs');

/////////////////////////////////////////////////////////////////
// Program wide constants and helpers
/////////////////////////////////////////////////////////////////

//
// Some helpers for terminating the program execution
//
const ERROR_SUCCESS_CODE = 0;
const ERROR_EXIT_CODE = 1;
const exitSuccess = () => process.exit(ERROR_SUCCESS_CODE);
const exitError = () => process.exit(ERROR_EXIT_CODE);

//
// We will set isDebugModeOn to true if --debug is passed as a
// command line flag
//
let isDebugModeOn = false;

//
// debugLog() is used to output text to stdin when --debug is passed
// to the executable
//
const debugLog = (...logContent) => {
  if (!isDebugModeOn) return;

  if (logContent.length > 0) {
    console.log('[debug] ', ...logContent);
  } else {
    console.log();
  }
}


/////////////////////////////////////////////////////////////////
// Helpers and constants for parsing the script args and options
/////////////////////////////////////////////////////////////////

//
// Usage and help messages
//
const USAGE_MESSAGE = "Usage: compiler [options] input_source_file -o output_file";
const OPTIONS_HELP_TEXT = "Options\n"
                          + "  -h --help               Print this help message\n"
                          + "  -o output_file          [required] Specifies the file to output our assembly to\n"
                          + "  --parse                 Stop the compilation process after parsing, exit with 0 if successful, 1 otherwise\n"
                          + "  --lex                   Stop the compilation process after lexing, exit with 0 if successful, 1 otherwise\n"
                          + "                          (this option overrides the --parse flag if both are set)\n"
                          + "  --debug                 if set, additional information will be output to stdin during the compliation process\n"

//
// Helper to print help text and exit with success code
//
const printHelpTextAndExitWithSuccessCode = () => {
  console.log(USAGE_MESSAGE);
  console.log();
  console.log(OPTIONS_HELP_TEXT);
  console.log();
  exitSuccess();
}

//
// Some error messages for invalid arguments
//      
const MISSING_OUTPUT_FILE_ERROR_MESSAGE = 'Must include output file in compiler invovation';
const MISSING_INPUT_FILE_ERROR_MESSAGE = 'Must include one input source file in compiler invovation';


//
// Helper to print invalid arguments error message and exit program execution
//
const printInvalidArgsMessageAndExitWithErrorCode = (errorMessage, secondaryMessage) => {
  console.log('Invalid Arguments'.concat(errorMessage ? `: ${errorMessage}` : ''));
  if (secondaryMessage) console.log('  '.concat(secondaryMessage));
  console.log();
  console.log(USAGE_MESSAGE);
  console.log();
  process.exit(ERROR_EXIT_CODE);
}


/////////////////////////////////////////////////////////////////
// Now lets parse the executable args
/////////////////////////////////////////////////////////////////

//
// to start let's get the args from process.argv
//
// process.argv[0] is the path to our node executable
// process.argv[1] is the path to this script
// process.argv[2] is the first arg passed to this script
const scriptArgs = process.argv.slice(2)

//
// Check if the debug flag is set
//
// first lets do a pass over the args and see if -h or --help is specfied. If so, we will
// output the help text and exit the program successfully
isDebugModeOn = scriptArgs.find((arg) => arg === '--debug');

//
// Check if the help flags are set and maybe exit early
//
// first lets do a pass over the args and see if -h or --help is specfied. If so, we will
// output the help text and exit the program successfully
if (scriptArgs.find((arg) => arg === '-h' || arg === '--help')) {
  printHelpTextAndExitWithSuccessCode();
}

//
// These are the bits of information we are trying to pull out of our args
//
// After looping over the args, we want to know the path to the input source
// file as well as the output source file, we also want to know what options
// were set using arguments
let inputSourceFile;
let outputFile;
let stopAfterLexingOptionSet = false;
let stopAfterParsingOptionSet = false;

//
// Helper predicate to determine if an arg is an option
//
const argIsOptionSyntax = (arg) => arg.search(/^-/) !== -1;

//
// Now lets loop over our args and process them
//
for (let currentArgsIndex = 0; currentArgsIndex < scriptArgs.length; currentArgsIndex++) {
  const currentArg = scriptArgs[currentArgsIndex];

  //
  // If arg looks like the output specifying option
  //
  if (currentArg === '-o') {
    const nextArgIndex = currentArgsIndex + 1;

    // ensure there there is an output file arg we can consume
    if (nextArgIndex >= scriptArgs.length) {
      printInvalidArgsMessageAndExitWithErrorCode(MISSING_OUTPUT_FILE_ERROR_MESSAGE);
    }

    // store the output file
    outputFile = scriptArgs[nextArgIndex];

    // advance the current index so we don't process the output file arg twice
    currentArgsIndex++;

    // start the loop again
    continue;
  }

  //
  // Check for flag options
  //
  if (argIsOptionSyntax(currentArg)) {
    switch (currentArg) {
      case '--lex':
        stopAfterLexingOptionSet = true;
        break;
      case '--parse':
        stopAfterParsingOptionSet = true;
        break;
    }
  }

  //
  // If arg is not an option, it specifies a file
  //
  if (!argIsOptionSyntax(currentArg)) {
    // if the input source file isn't already set, we can store this
    // args as the input source and go to the next invocation
    if (!inputSourceFile) {
      inputSourceFile = currentArg;
      continue;

    } else {
      printInvalidArgsMessageAndExitWithErrorCode(
        MISSING_INPUT_FILE_ERROR_MESSAGE,
        `at least two input source files specificed: ${inputSourceFile} and ${currentArg}`
      );
    }
  }
}

//
// We require an input source file to be specified
//
if (!inputSourceFile) {
  printInvalidArgsMessageAndExitWithErrorCode(
    MISSING_INPUT_FILE_ERROR_MESSAGE
  );
}

//
// We also require an output file to be specified
//
if (!outputFile) {
  printInvalidArgsMessageAndExitWithErrorCode(
    MISSING_OUTPUT_FILE_ERROR_MESSAGE 
  );
}

//
// Use debug log to indicate what information we've extracted from the command line args
//
debugLog('---------------------------------------------');
debugLog('COMMAND LINE ARG PARSING');
debugLog('Results of parsing command line arguments');
debugLog('  - inputSourceFile:', inputSourceFile);
debugLog('  - outputFile:', outputFile);
debugLog('  - stopAfterLexingOptionSet:', stopAfterLexingOptionSet);
debugLog('  - stopAfterParsingOptionSet:', stopAfterParsingOptionSet);
debugLog();

/////////////////////////////////////////////////////////////////
// Lex our input source file
/////////////////////////////////////////////////////////////////
debugLog('---------------------------------------------');
debugLog('LEXING');

//
// The output from the lexing stage will be list of tokens
//
const tokens = [];

//
// Each of those tokens will have a tokenType field that has one
// of the token types below
//
const TOKEN_TYPES = {
  LEFT_PAREN: 'LEFT_PAREN',
  RIGHT_PAREN: 'RIGHT_PAREN',
  OPEN_BRACE: 'OPEN_BRACE',
  CLOSE_BRACE: 'CLOSE_BRACE',
  SEMI_COLON: 'SEMI_COLON',
  INT_KEYWORD: 'INT_KEYWORD',
  VOID_KEYWORD: 'VOID_KEYWORD',
  RETURN_KEYWORD: 'RETURN_KEYWORD',
  IDENTIFIER: 'IDENTIFIER',
  CONSTANT: 'CONSTANT',
};

//
// While parsing the input text, we will use a number of predicate
// helpers that make it easy to identify which character class a
// specific character is part of
//
const isLowerCaseCharacter = (char) =>
  char.charCodeAt(0) >= 'a'.charCodeAt(0)
  && char.charCodeAt(0) <= 'z'.charCodeAt(0);

const isUpperCaseCharacter = (char) =>
  char.charCodeAt(0) >= 'A'.charCodeAt(0)
  && char.charCodeAt(0) <= 'Z'.charCodeAt(0);

const isAlphabetCharacter = (char) =>
  isLowerCaseCharacter(char)
  || isUpperCaseCharacter(char);

const isNumericCharacter = (char) =>
  char.charCodeAt(0) >= '0'.charCodeAt(0)
  && char.charCodeAt(0) <= '9'.charCodeAt(0);

const isAlphaNumericCharacter = (char) =>
  isAlphabetCharacter(char)
  || isNumericCharacter(char);

const isIdentifierStartingCharacter = (char) =>
  isAlphabetCharacter(char)
  || char === '_';

const isIdentifierNonStartingCharacter = (char) =>
  isAlphaNumericCharacter(char)
  || char === '_';

const isWhiteSpaceCharacter = (char) =>
  char.charCodeAt(0) === 32 // space
  || char.charCodeAt(0) === 9 // tab
  || char.charCodeAt(0) === 10 // line feed
  || char.charCodeAt(0) === 13; // carriage return

const isWordBoundaryCharacter = (char) =>
  !(
    isAlphaNumericCharacter(char)
    || char === '_'
  );

//
// Let's get the text from our input source file.
// readFileSync() will output a buffer of bytes for us to read
//
const sourceFileTextBuffer = fs.readFileSync(inputSourceFile);

debugLog('bcalrborg incoming program buffer bytes:');
debugLog(sourceFileTextBuffer);
debugLog('bcalrborg incoming program buffer string:');
debugLog(sourceFileTextBuffer.toString('ascii'));

//
// We are going to loop over the bytes in our input one at a time.
// Sometimes, we will need to look ahead a few bytes from our current Index,
// in these cases we will use runner to look ahead.
//
let currentIndex = 0;
let runner = 1;

//
// Now lets build some helpers for easily viewing the current and upcoming
// characters in our input buffer
//
const currentChar = () => String.fromCharCode(sourceFileTextBuffer[currentIndex]);

//
// advance will increment our currentIndex and take us to the next character
//
const advance = (charactersAhead) => {
  currentIndex += charactersAhead;
}

//
// peek will return characters ahead of our current index based on charactersAhead.
// if charactersAhead is 2, we look two characters ahead of the current char
//
const peek = (charactersAhead) => {
  const peekIndex = currentIndex + charactersAhead;

  if (peekIndex >= sourceFileTextBuffer.length) {
    return 0;
  }

  return String.fromCharCode(sourceFileTextBuffer[peekIndex]);
}

//
// Now we will loop over the characters in our input and add tokens
// as we go.
//
while (currentIndex < sourceFileTextBuffer.length) {
  switch (true) {
    case isWhiteSpaceCharacter(currentChar()):
      advance(1);
      break;

    case currentChar() === '(':
      tokens.push({tokenType: TOKEN_TYPES.LEFT_PAREN});
      advance(1);
      break;

    case currentChar() === ')':
      tokens.push({tokenType: TOKEN_TYPES.RIGHT_PAREN});
      advance(1);
      break;

    case currentChar() === ';':
      tokens.push({tokenType: TOKEN_TYPES.SEMI_COLON});
      advance(1);
      break;

    case currentChar() === '{':
      tokens.push({tokenType: TOKEN_TYPES.OPEN_BRACE});
      advance(1);
      break;

    case currentChar() === '}':
      tokens.push({tokenType: TOKEN_TYPES.CLOSE_BRACE});
      advance(1);
      break;

    case currentChar() === 'i':
      if (peek(1) === 'n' && peek(2) === 't') {
        tokens.push({ tokenType: TOKEN_TYPES.INT_KEYWORD})
        advance(3);
        break;
      }

    case currentChar() === 'v':
      if (peek(1) === 'o' && peek(2) === 'i' && peek(3) === 'd') {
        tokens.push({ tokenType: TOKEN_TYPES.VOID_KEYWORD})
        advance(4);
        break;
      }

    case currentChar() === 'r':
      if (peek(1) === 'e' && peek(2) === 't' && peek(3) === 'u' && peek(4) === 'r' && peek(5) === 'n') {
        tokens.push({ tokenType: TOKEN_TYPES.RETURN_KEYWORD})
        advance(6);
        break;
      }

    case isIdentifierStartingCharacter(currentChar()):
      //
      // as we look ahead and find new characters to go in this identifier
      // we will put them in identifierCharacters
      //
      const identifierCharacters = [currentChar()];

      //
      // use the runner to look ahead and keep checking if the characters
      // are valid identifier chars
      //
      runner = 1;
      while (isIdentifierNonStartingCharacter(peek(runner))) {
        identifierCharacters.push(peek(runner))
        runner += 1;
      }

      //
      // Finally, the character after the identifier needs to be a word
      // boundary character
      //
      if (!isWordBoundaryCharacter(peek(runner))) {
        console.error(
          `Lexing Error: invalid constant token starting at ${currentIndex}`
        );
        exitError();
      }


      //
      // Now that we have confirmed runner iterates over a valid identifier,
      // we can take all the chars we found and make a string of them
      //
      const identifier = identifierCharacters.join('');
      tokens.push({ tokenType: TOKEN_TYPES.IDENTIFIER, text: identifier })

      //
      // advance forward past all of the characters in our identifier
      //
      advance(runner);
      break;

    case isNumericCharacter(currentChar()):
      //
      // as we look ahead and find new characters to go in this constant
      // we will put them in constantCharacters 
      //
      const constantCharacters = [currentChar()];

      //
      // use the runner to look ahead and keep checking if the characters
      // are valid constant chars
      //
      runner = 1;
      while (isNumericCharacter(peek(runner))) {
        constantCharacters.push(peek(runner))
        runner += 1;
      }

      //
      // finally, the character after the constant needs to be a word
      // boundary character
      //
      if (!isWordBoundaryCharacter(peek(runner))) {
        console.error(
          `Lexing Error: invalid constant token starting at ${currentIndex}`
        );
        exitError();
      }

      //
      // now lets take all the chars we found and put them together into
      // a string to make a token out of
      //
      const constant = constantCharacters.join('');
      tokens.push({ tokenType: TOKEN_TYPES.CONSTANT, text: constant })

      //
      // advance the runner forward so that we don't process all of the
      // same characters again
      //
      advance(runner);
      break;

    default:
      //
      // if we can't identify a token to associate with this character
      // we need to throw an error and exit early
      //
      console.error(
        "Lexing error: unknown character with ascii code:", currentChar().codePointAt(0)
      );
      exitError();
  }
}

debugLog('tokens lexed from program text:')
debugLog(...tokens.map(token => {
  if (
    token.tokenType === TOKEN_TYPES.IDENTIFIER
    || token.tokenType === TOKEN_TYPES.CONSTANT
  ) {
    return [token.tokenType, ':', token.text].join('');
  }

  return token.tokenType
}));
debugLog();

//
// exit early if --lex command line flag was passed
//
if (stopAfterLexingOptionSet) {
  debugLog('EXITING PROGRAM EARLY: exiting after lexing because --lex was set');
  exitSuccess();
}


/////////////////////////////////////////////////////////////////
// Parse the tokens we found
/////////////////////////////////////////////////////////////////

debugLog('---------------------------------------------');
debugLog('PARSING');
debugLog();
debugLog('We will attempt to extract an AST from the tokens that were generated in lexing.');
debugLog();

//
// We'll create a copy of our token list to iterate over when we are parsing
//
// We'll use the methods currentToken(), resetCurrentTokenIndex(), advanceToken()
// to process the current and upcoming tokens while we are parsing.
//
const parsingTokens = [...tokens];
let currentTokenIndex = 0;

const resetCurrentTokenIndex = (newIndex) => currentTokenIndex = newIndex;

const currentToken = () => {
  if (currentTokenIndex >= parsingTokens.length) {
    return null;
  }

  return parsingTokens[currentTokenIndex];
}

const tokenStreamHasRemainingOutput = () => currentTokenIndex <= parsingTokens.length - 1;

const advanceToken = (count) => currentTokenIndex += count;


//
// Here we specify all of the abstract syntax tree node types that we wish
// to support.
//
const AST_NODE_TYPES = {
  PROGRAM_NODE: 'PROGRAM_NODE',
  FUNCTION_NODE: 'FUNCTION_NODE',
  STATEMENT_NODE: 'STATEMENT_NODE',
  EXPRESSION_NODE: 'EXPRESSION_NODE',
  IDENTIFIER_NODE: 'IDENTIFIER_NODE',
  INTEGER_NODE: 'INTEGER_NODE',
}

//
// We will want to pretty print our ast, and it will be useful to have a
// helper to generate the appropriate indent level strings as our AST
// nodes nest.
//
const BASE_INDENT = '  ';
const indentString = (indentLevel) => {
  let outputString = '';
  for (let i = 0; i < indentLevel; i++) {
    outputString = outputString.concat(BASE_INDENT);
  }
  return outputString;
}

//
// We will definie a nodeParser() for each ast node.
// This parser will attempt to parse that particular AST
// node at the current token.
//
// For all intents and purposes, this function is our "parser".
// when we call this function, we process our token inputs
// and attempt to craete an AST with a program AST node as root
//

// All ASTs for our project have program as a root
function programParser() {
  const functionNode = functionParser();

  //
  // if we couldn't identify a program AST node, then our parsing failed
  //
  if (!functionNode) {
    console.error('Parsing error: unable to identify valid parse for input program');
    exitError();
  }

  //
  // If we found a program AST node, but there were still additional tokens after
  // the input, then our parsing failed. Every token should be a decendant of our
  // root program node.
  //
  if (tokenStreamHasRemainingOutput()) {
    console.error('Parsing error: dangling tokens after program');
    exitError();
  }

  return {
    nodeType: AST_NODE_TYPES.PROGRAM_NODE,
    functionChild: functionNode,
    debugPrettyPrint: () => {
      debugLog('Program(');
      functionNode.debugPrettyPrint(1);
      debugLog(')');
    }
  }
}

// Parse an entire function declaration with its return type, name, args and body
function functionParser() {
  const resetTokens = () => resetCurrentTokenIndex(currentTokenIndex);

  // parse the return type of the function
  const intFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.INT_KEYWORD);
  if (!intFound) {
    resetTokens();
    return null;
  }

  // parse the name of the fucntion
  const functionNameIdentifierNode = identifierParser();
  if (!functionNameIdentifierNode) {
    resetTokens();
    return null;
  }

  // parse left paren
  const leftParenFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.LEFT_PAREN);
  if (!leftParenFound) {
    resetTokens();
    return null;
  }

  // parse args
  const voidFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.VOID_KEYWORD);
  if (!voidFound) {
    resetTokens();
    return null;
  }

  // parse left paren around args
  const rightParenFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.RIGHT_PAREN);
  if (!rightParenFound) {
    resetTokens();
    return null;
  }

  // open curly brace aound the function body
  const openingCurlyBraceFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.OPEN_BRACE);
  if (!openingCurlyBraceFound) {
    resetTokens();
    return null;
  }

  // function body statement
  const statementNode = statementParser();
  if (!statementNode) {
    resetTokens();
    return null;
  }

  // closing curly brace around function body
  const closingCurlyBraceFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.CLOSE_BRACE);
  if (!closingCurlyBraceFound) {
    resetTokens();
    return null;
  }

  return {
    nodeType: AST_NODE_TYPES.FUNCTION_NODE,
    returnType: 'int',
    functionNameIdentifier: functionNameIdentifierNode,
    functionArgs: 'void',
    functionBody: statementNode,
    debugPrettyPrint: (indentLevel) => {
      const indents = indentString(indentLevel);
      const innerIndents = indents.concat(BASE_INDENT);
      debugLog(`${indents}Function(`);
      debugLog(`${innerIndents}returnType=${'int'}`);
      debugLog(`${innerIndents}functionIdentifier=${functionNameIdentifierNode.text}`);
      debugLog(`${innerIndents}functionArgs=${'args'}`);
      debugLog(`${innerIndents}functionBody=`);
      statementNode.debugPrettyPrint(indentLevel + 2);
      debugLog(`${indents})`);
    }
  }
}

// parse any statement
function statementParser() {
  const resetTokens = () => resetCurrentTokenIndex(currentTokenIndex);

  //
  // Currently, we are only parsing return statements, these checks can most likely
  // be broken out into their own function returnStatementParser() when we add other
  // new statements.
  //

  const returnFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.RETURN_KEYWORD);
  if (!returnFound) {
    resetTokens();
    return null;
  }

  const expressionNode = expressionParser();
  if (!expressionNode) {
    resetTokens();
    return null;
  }

  const semiColonFound = verifyConcreteTokenAndAdvance(TOKEN_TYPES.SEMI_COLON);
  if (!semiColonFound) {
    resetTokens();
    return null;
  }
  
  return {
    nodeType: AST_NODE_TYPES.STATEMENT_NODE,
    expression: expressionNode,
    debugPrettyPrint: (indentLevel) => {
      const indents = indentString(indentLevel);
      const innerIndents = indents.concat(BASE_INDENT);
      debugLog(`${indents}Statement(`);
      debugLog(`${innerIndents}expression=`);
      expressionNode.debugPrettyPrint(indentLevel + 2);
      debugLog(`${indents})`);

    }
  }
}

// parse any expression
function expressionParser() {
  const resetTokens = () => resetCurrentTokenIndex(currentTokenIndex);

  // for now we only process expressions which are a single constant int
  const intNode = integerParser();
  if (!intNode) {
    resetTokens();
    return null;
  }

  return {
    nodeType: AST_NODE_TYPES.EXPRESSION_NODE,
    expression: intNode,
    debugPrettyPrint: (indentLevel) => {
      const indents = indentString(indentLevel);
      const innerIndents = indents.concat(BASE_INDENT);
      debugLog(`${indents}Expression(`);
      debugLog(`${innerIndents}expressionValue=`);
      intNode.debugPrettyPrint(indentLevel + 2);
      debugLog(`${indents})`);
    }
  }
}

// parse any identifier
function identifierParser() {
  const resetTokens = () => resetCurrentTokenIndex(currentTokenIndex);

  // check to ensure there is some type of identifier at our current
  // token
  const potentialIdentifier = currentToken();
  if (potentialIdentifier.tokenType !== TOKEN_TYPES.IDENTIFIER) {
    resetTokens();
    return null;
  }

  advanceToken(1);
  return {
    nodeType: AST_NODE_TYPES.IDENTIFIER_NODE,
    identifierName: potentialIdentifier.text,
  }
}

// parse any integer constant
function integerParser() {
  const resetTokens = () => resetCurrentTokenIndex(currentTokenIndex);
  
  const potentialInteger = currentToken();
  if (potentialInteger.tokenType !== TOKEN_TYPES.CONSTANT) {
    resetTokens();
    return null;
  }

  advanceToken(1);

  return {
    nodeType: AST_NODE_TYPES.INTEGER_NODE,
    integer: potentialInteger.text,
    debugPrettyPrint: (indentLevel) => {
      const indents = indentString(indentLevel);
      const innerIndents = indents.concat(BASE_INDENT);
      debugLog(`${indents}Constant(`);
      debugLog(`${innerIndents}constantValue=${potentialInteger.text}`);
      debugLog(`${indents})`);
    }
  }
}


//
// Sometimes in parsing we need to verify that a token is preset, but we do not
// actually want to create an AST node for that token. For example, when parsing
// an expression, we must verify that ';' is the last token in the statement.
//
// verifyConcreteTokenAndAdvance() allows us to do just that. It will tell us if
// a particular token type can be found at the current token position in our input
// stream. 
//
function verifyConcreteTokenAndAdvance(tokenType) {
  if (currentToken()?.tokenType === tokenType) {
    advanceToken(1);
    return true;
  }

  return false;
}


//
// This is the magic moment when we call our parser and process our input tokens!
//
const abstractSyntaxTree = programParser();

//
// Log a console friendly version of our AST for debugging purposes
//
debugLog('While parsing, the following ast was generated:');
abstractSyntaxTree.debugPrettyPrint();
debugLog();

//
// if the --parse command line option was set, we can exit here!
//
if (stopAfterParsingOptionSet) {
  debugLog('exiting after parsing because --parse flag was passed')
  exitSuccess();
}


/////////////////////////////////////////////////////////////////
// Create our output file
/////////////////////////////////////////////////////////////////

fs.writeFileSync(outputFile, 'foobar\n');
exitSuccess();
